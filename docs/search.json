[
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "",
    "section": "",
    "text": "Use this repository to host a website for your CASA0025 final project by following these stpes:\n\nclone this repository\ninstall quarto\nedit the ‘index.qmd’ file with the contents of your project\nusing terminal, navigate to the project directory and run “quarto render”\npush the changes to your github repository\non github, navigate to Settings&gt;Pages&gt;Build and Deployment. Make sure that under “Source” it says “deploy from branch”. Under “Branch”, select “Main” in the first dropdown and “Docs” under the second drop down. Then press “Save”\n\nYour website should now be available under https://{your_username}.github.io/{your_repo_name}\n\nwebsite for this template\nrepo for application codes"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0025 Group Project – Heat Stress Vulnerability Index (HSVI)",
    "section": "",
    "text": "Fill in the sections below to provide a brief summary of your project. Each section should have no more than 100 words. Do not edit any of the headings.\n\n\nWhat is the problem you’re trying to address using this application?\nUrban areas are becoming increasingly warmer than their surrounding areas known as the Urban Heat Island (UHI) effect (Wu et al., 2021). Moreover, heat stress is the leading cause of weather-related deaths and can exacerbate underlying illnesses (WHO, 2024). Studies have shown that estimates of heat-related mortality vary significantly depending on whether residents are assumed to acclimatise to local or city-wide temperatures (Shindell, 2024). Therefore, a web application that integrates temperature data, acclimatisation factors, and demographic vulnerability at a higher resolution would improve localised policy improvements and safety measures.\n\n\n\nWho are you building this application for? How does it address a need this community has?\nThis application is designed for various stakeholders who play a role in protecting London from extreme heat. These include governing authorities, public health bodies, and infrastructure providers. ​​It allows users to identify heat hotspots across the city in near real-time. This improves on static snapshot data (Arup, 2024), enabling more dynamic heat risk management. The application can also be used to inform city-wide policies, and enable localised public health responses during heat waves. Finally, it can be used to evaluate how infrastructure impacts heat stress and encourage precautionary and safety measures.\n\n\n\nWhat data are you using?\nGeospatial datasets from various sources are used: Sentinel-2 satellite imagery for NDVI (vegetation health), Landsat 8 Tier 1 for land surface temperature, Ordnance Survey for building mass density, and Nomis census data to capture old age demographics. These datasets are integrated and analysed to produce an index of heat vulnerability across urban areas.\n\n\n\nLayer/Factor\nDataset\nResolution\nTimeframe\nLink\n\n\n\n\nPopulation density (elderly)\ncensus2021-ts007-msoa.csv\nVector (MSOA)\nAs at 2021\nONS Census 2021\n\n\nNDVI\nSentinel 2 Bands 4 and 8\n10m\n3-4 days\nEarth Engine Data Catalog Sentinel-2\n\n\nTemperature (LST)\nLandsat 8 Surface Temperature Band 10\n30m\n16 days ; Month filter:6-9\nEarth Engine Data Catalog Landsat 8\n\n\nBuilding height and density\nOrdnance Survey National Geographic Database (OS NGD) Buildings\nvector\n2025\nOS NGD Documentation\n\n\n\n\n\n\nHow are you using this data to address the problem?\nThis application was built using Streamlit and integrates with Google Earth Engine (GEE). Data is fetched from GEE (Sentinel-2 for vegetation, Landsat 8 for temperature), OS NGD and the UK census. The index was created by first inverting the NDVI values, since more vegetation lowers heat risk, and then scaling all datasets between 0 and 1 using MinMaxScaler before combining them. Every factor is then weighted equally at 25%, and the weighted scores are summed to generate a final Heat Stress Vulnerability Index (HSVI). The results are then presented through an interactive map, enabling stakeholders to identify areas most at risk.\n\n\n\nHow does your application’s interface work to address the needs of your end user?\nThe interface features a dual-panel design for HSVI calculation. The left-control panel allows users to select data aggregated at different geographic levels (LAD or council), date ranges, and map topics (overall index or specific factors like NDVI, temperature, elderly population, and building mass density). The right panel displays responsive interactive choropleth maps and bar charts showing top 10 areas needing prior actions to tackle heat stress. Users can also download CSV files for external analysis. This design helps users identify vulnerable communities and understand specific heat-risk factors, supporting future interventions.\n\n\n\n\nEach time users change map layers in application, please use “Reset APP” botton to refresh the page to avoid cache problmes.\nApplication Website: https://casa0025-test.streamlit.app\n\n\n\n\n\n\n\nUse this section to explain how your application works using code blocks and text explanations (no more than 500 words excluding code):\nClick here to access the repo to find Home.py which includes all codes for the application.\n\n\n\nTechnical Walkthrough\n\n\n\n\nUrban heat disproportionately affects segments of the population; people over the age of 65 represent the largest of these groups. We use this group as a proxy for vulnerable population groups within our application. The data used to size this group is from the UK 2021 Census. Data is aggregated at the lowest available level of aggregation (MSOA) and is summed together.\nThis is then divided by the total population for that location “Total Number of Usual Residents” to arrive at a Percentage of the population aged 65 and over. The rate value is used as part of the HSVI, however, in practice there are minor differences when compared to using absolute counts, so rates are preferred.\n# 2️ Convert GeoDataFrame → EE FeatureCollection\n                    if st.session_state.london_boroughs_over_65 is None:\n                        # now we're going to add in the vector data for the london boroughs for number of people over 65 from a geojson file\n                        # london_boroughs_over_65 = gp.read_file('data/london_percentage_of_population_over_65.geojson')#.head(10).to_crs(4326)\n                        london_boroughs_over_65 = pd.read_parquet('data/london_percentage_of_population_over_65.parquet.gzip')\n\n\n\n                        # load the lsoa level geometries\n                        # gdf_lsoas = pd.read_parquet('data/london_lsoas_2011_mapping_file.parquet.gzip')\n                        gdf_lsoas = pd.read_parquet('data/london_msoas_2021_mapping_file.parquet.gzip')\n                        # convert the wkt geometry to a shapely geometry\n                        gdf_lsoas[\"geometry\"] = gdf_lsoas[\"geometry\"].apply(shapely.wkt.loads)\n                        # convert this to a geodataframe\n                        gdf_lsoas = gp.GeoDataFrame(gdf_lsoas, geometry=\"geometry\", crs=4326)\n                        # filter the LAD11NM column to match the users  \n                        gdf_boroughs = gdf_lsoas[gdf_lsoas[\"LAD11NM\"] == st.session_state.selected_council]\n                        gdf_boroughs = gdf_boroughs[[\"MSOA21CD\"]].rename(columns={\"MSOA21CD\":\"geography code\"})\n\n\n                        # do a spatial join to get the vulnerable population data for the selected council\n                        london_boroughs_over_65 = london_boroughs_over_65.merge(gdf_boroughs, on=\"geography code\")\n\n                        # convert the wkt geometry to a shapely geometry\n                        london_boroughs_over_65[\"geometry\"] = london_boroughs_over_65[\"geometry\"].apply(shapely.wkt.loads)\n                        # convert this to a geodataframe\n                        london_boroughs_over_65 = gp.GeoDataFrame(london_boroughs_over_65, geometry=\"geometry\", crs=4326)\n\n\n                        # add this to session state\n                        st.session_state.london_boroughs_over_65 = london_boroughs_over_65\n                    else:\n                        london_boroughs_over_65 = st.session_state.london_boroughs_over_65\n\n\n\n\n                    # calculate the midpoint of london\n                    london_midpoint_latitude, london_midpoint_longitude = london_boroughs_over_65.to_crs(4326).geometry.centroid.y.mean(), london_boroughs_over_65.to_crs(4326).geometry.centroid.x.mean()\n                    \n\n                    # rename columns for the map\n                    london_boroughs_over_65 = london_boroughs_over_65.rename(columns={\"pct_over_65_pop\":\"Population over 65 %\",\n                                                                                      \"total_pop_over_65_years_old\":\"Total Population over 65\",\n                                                                                      \"total_pop\":\"Total Population\"})\n                    london_boroughs_over_65 = london_boroughs_over_65.drop(columns=[\"date\",\"city\"])\n                    # round the % population over 65 to 2 decimal places\n                    london_boroughs_over_65[\"Population over 65 %\"] = (london_boroughs_over_65[\"Population over 65 %\"] * 100).round(2)\n\n                    if st.session_state.london_boroughs_over_65_map is None:\n                        # we'll plot this on a folium map\n                        m = london_boroughs_over_65.explore(\"Population over 65 %\", tiles=\"CartoDB.Positron\", cmap=\"Blues\", scheme=\"Quantiles\", legend_title=\"Population over 65\", style_kwds={'weight': 1})\n\n\n\nHealthy vegetation cools surrounding areas through shade and evapotranspiration which is why it is incorporated in the index. Healthy plants absorb red light and reflect near-infrared (NIR) light. NDVI captures the contrast between NIR and Red reflectance, allowing us to identify areas of healthy vegetation. Areas with NDVI values close to 1 indicate healthy vegetation, while low or negative values suggest sparse vegetation.\nNDVI is calculated using this formula:\n\\[\nNDVI = \\frac{(NIR - Red)}{(NIR + Red)}\n\\]\nWhere:\n\n\\(NDVI\\): Normalized Difference Vegetation Index\n\n\\(NIR\\): Reflectance in the Near-Infrared band\n\n\\(Red\\): Reflectance in the Red band\n\nSentinel-2 data was cloud-filtered and combined using the median value of the available images in GEE. NDVI values were calculated from band 4 (Red) and band 8 (Near-infrared). Then spatially aggregated by borough using a median reducer at 10m resolution.\n# now we're going to use the lad data to get the NDVI\n                    if st.session_state.gdf_results is None:\n\n\n                        # 2️ Convert GeoDataFrame → EE FeatureCollection\n                        ee_boroughs = geemap.geopandas_to_ee(gdf_boroughs, geodesic=False)\n                        st.session_state.ee_boroughs = ee_boroughs\n                        # 3️ Build Sentinel‑2 NDVI composite\n                        sentinel = (\n                            ee.ImageCollection('COPERNICUS/S2_SR')\n                            .filterBounds(ee_boroughs)\n                            .filterDate(one_year_ago, today)\n                            .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\n                            .median()\n                            .clip(ee_boroughs)\n                        )\n\n                        # this was the default code for the NDVI\n                        ndvi = sentinel.normalizedDifference(['B8', 'B4']).rename('NDVI')\n                        st.session_state.ndvi = ndvi\n\n                        # 4️ Sum NDVI per borough\n                        fc_results = ndvi.reduceRegions(\n                            collection=ee_boroughs,\n                            reducer=ee.Reducer.median(),\n                            scale=10,\n                            crs='EPSG:27700'\n                        )\n                        \n                        # 5️⃣Pull results client‑side as GeoJSON → GeoDataFrame\n                        geojson = fc_results.getInfo()\n                        \n                        gdf_results = gp.GeoDataFrame.from_features(geojson['features']).rename(columns={'NAME': 'MSOA Name',\"median\": \"NDVI\"})\n                        # for ndvi we will need to invert these values \n                        gdf_results[\"NDVI\"] = 1 / gdf_results[\"NDVI\"]\n\n                        st.session_state.gdf_results = gdf_results\n\n\n\nLand Surface Temperature (LST) represents heat energy emitted by land, buildings, and other surfaces, serving as an indirect measure of air temperature during heat waves (United States Environmental Protection Agency, 2025). Using Landsat 8 Surface Temperature Band 10 in GEE, processed LST was derived for summer months (June-September) when peak heat conditions are experienced.\nWe filtered out cloudy images, before applying a median reducer and a water mask excluding water bodies to focus on artificial surfaces that retain more heat, relevant to urban populations. Spatial aggregation was finally done at LSOA and Borough levels.\n # load the data and apply the relevant filters and functions\n                    #.filter(ee.Filter.calendarRange(6, 9,'month')) \\  may apply a similar seasonal filter here\n                    if st.session_state.date_range_selection == \"Yes\":\n                        landsat = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n                        .filterDate(st.session_state.user_selected_start_date, st.session_state.user_selected_end_date) \\\n                        .filter(ee.Filter.calendarRange(6, 9, 'month'))\\\n                        .filterBounds(ee_boroughs) \\\n                        .filter(ee.Filter.lt(\"CLOUD_COVER\", 15)) \\\n                        .map(applyScaleFactors) \\\n                        .select('ST_B10').map(celsius) \\\n                        .reduce(ee.Reducer.median()) \\\n                        .clip(ee_boroughs)\n                    elif st.session_state.date_range_selection == \"No\":\n                        landsat = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n                        .filterDate(one_year_ago, today) \\\n                        .filter(ee.Filter.calendarRange(6, 9, 'month'))\\\n                        .filterBounds(ee_boroughs) \\\n                        .filter(ee.Filter.lt(\"CLOUD_COVER\", 15)) \\\n                        .map(applyScaleFactors) \\\n                        .select('ST_B10').map(celsius) \\\n                        .reduce(ee.Reducer.median()) \\\n                        .clip(ee_boroughs)\n                    # mask out water in London to detect more accurate LST result\n                    # Generate a water mask.\n                    water = ee.Image(\"JRC/GSW1_4/GlobalSurfaceWater\").select(\"occurrence\")\n                    notWater = water.mask().Not()\n                    temperature_layer = landsat.updateMask(notWater)\n\n                    st.session_state.temperature_layer = temperature_layer\n\n                    # 4️ Sum NDVI per borough\n                    temperature_results = temperature_layer.reduceRegions(\n                        collection=ee_boroughs,\n                        reducer=ee.Reducer.median(),\n                        scale=10,\n                        crs='EPSG:27700'\n                    )\n                            \n                    # 5️⃣Pull results client‑side as GeoJSON → GeoDataFrame\n                    geojson = temperature_results.getInfo()\n                    \n                    temperature_gdf_results = gp.GeoDataFrame.from_features(geojson['features']).rename(columns={'NAME': 'MSOA Name',\"median\": \"surface_temperature\"})\n\n\n\nDensely built environments contribute to higher heat absorption and slower cooling. Therefore, Building Mass Density (BMD) is considered as part of the Urban Heat Island (UHI) index. BMD has been calculated at both the LSOA and Borough levels.\nThe Ordnance Survey National Geographic Database (OS NGD) was used as the most complete and authoritative building dataset available in Great Britain. OS NGD was chosen over OpenStreetMap (OSM) due to its more comprehensive and consistent height attribution, which is sparse and unreliable in OSM (Bernard et al., 2022).\nBMD was calculated using the following formula:\n\\[\nBmd = \\frac{\\sum (H_i \\times A_i)}{A_{admin}}\n\\]\nWhere:\n\n\\(Bmd\\): Building Mass Density\n\\(H_i\\): Height of building \\(i\\) (in metres)\n\\(A_i\\): Footprint area of building \\(i\\) (in square metres)\n\\(A_{admin}\\): Total area of the administrative region (in square metres)\n\n## Process total building volumes per lsoa\n# This is split into batches to prevent time out issues.\n\n# Get list of all LSOA codes\nlsoa_codes = con.execute(\"\"\"\n    SELECT DISTINCT LSOA21CD\n    FROM london_lsoa;\n    \"\"\").fetchdf()['LSOA21CD'].tolist()\n\n# Split into batches\nbatch_size = 250\nbatches = [lsoa_codes[i:i + batch_size] for i in range(0, len(lsoa_codes), batch_size)]\n\n# Create the table before the loop if it doesn't exist\ncon.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS london_LSOAs_vol (\n        LSOA21CD VARCHAR PRIMARY KEY,\n        borough VARCHAR,\n        building_count INTEGER,\n        total_volume DOUBLE,\n        geom GEOMETRY\n    )\n\"\"\")\n\nfor batch in batches:\n    # Convert to SQL IN clause\n    code_list = ','.join(f\"'{code}'\" for code in batch)\n\n    # create query to insert data into new london_LSOAs_vol table\n    query = f\"\"\"\n        INSERT INTO london_LSOAs_vol\n        SELECT\n            l.LSOA21CD,\n            l.Borough AS borough,\n            COUNT(*) AS building_count,\n            SUM(b.volume) AS total_volume,\n            l.geom\n        FROM london_lsoa l\n        JOIN buildings b\n        ON ST_Intersects(l.geom, ST_GeomFromText(b.geometry))\n        WHERE l.LSOA21CD IN ({code_list})\n        GROUP BY l.LSOA21CD, l.geom, l.Borough;\n    \"\"\"\n    # execute the query created above\n    con.execute(query)\n\n\n# Calculate the building mass density\n# Building Mass Density = LSOA area x total building volume\n\n# Calculate area for each LSOA (assuming CRS in meters)\ncon.execute(\"\"\"\n    ALTER TABLE london_LSOAs_vol ADD COLUMN area_m2 DOUBLE;\n    UPDATE london_LSOAs_vol\n    SET area_m2 = ST_Area(geom);\n\"\"\")\n\n# Calculate building mass density for each LSOA\ncon.execute(\"\"\"\n    ALTER TABLE london_LSOAs_vol ADD COLUMN building_mass_density DOUBLE;\n    UPDATE london_LSOAs_vol\n    SET building_mass_density = total_volume / area_m2;\n\"\"\")\n\n\n\nThen we combine four factors above to calculate the index:\n# okay so now we're going to normalise the data values  using sklearn min max scaler\n                    scaler = MinMaxScaler()\n                    # first we'll get the columns we want to normalise\n                    columns_to_normalise = [\"ndvi\",\"surface_temperature\",\"pct_over_65_pop\",\"building_density\"]\n                    for column in columns_to_normalise:\n                        raw_index_values_gdf_boroughs[f\"{column}_normalised\"] = scaler.fit_transform(raw_index_values_gdf_boroughs[[column]])\n                    # st.write(\"Normalised dataframe\")\n                    # st.dataframe(raw_index_values_gdf_boroughs)\n                    # ------------------------------------------------------------\n                    normalised_columns = [x for x in raw_index_values_gdf_boroughs.columns if \"normalised\" in x]\n                    for column in normalised_columns:\n                        # now we're going to weight this by 25% for each of the normalised values\n                        raw_index_values_gdf_boroughs[f\"{column}_weighted\"] = raw_index_values_gdf_boroughs[column] * 0.25\n                    # st.write(\"Weighted dataframe\")\n                    weighted_df = raw_index_values_gdf_boroughs[[\"borough_name\"]+[x for x in raw_index_values_gdf_boroughs.columns if \"weighted\" in x] + [\"geometry\"]]\n                    # st.dataframe(weighted_df)\n                    # ------------------------------------------------------------\n                    # now lastly we're going to sum these up to get the final index values\n                    weighted_df[\"index_value\"] = weighted_df[[x for x in weighted_df.columns if \"weighted\" in x]].sum(axis=1)\n                    weighted_columns = [x for x in weighted_df.columns if \"weighted\" in x]\n                    # st.write(\"Final index dataframe\")\n                    # st.dataframe(weighted_df.rename(columns={\"borough_name\":\"Location\"}).drop(columns=[\"geometry\"]))\n                    # ------------------------------------------------------------\n\n\n\n\nArup. (2024) Urban heat snapshot. Available at: https://www.arup.com/insights/publication-urban-heat-snapshot/ (Accessed: 20 April 2025).\nBernard, J. et al. (2022) ‘Estimation of missing building height in OpenStreetMap data: a French case study using GeoClimate 0.0.1’, Geoscientific Model Development, 15(19), pp. 7505–7532. Available at: (https://doi.org/10.5194/gmd-15-7505-2022).\nShindell, D., Hunter, R., Faluvegi, G., & Parsons, L (2024). ‘Premature deaths due to heat exposure: The potential effects of neighborhood-level versus city-level acclimatization within US cities’, GeoHealth, 8.\nUnited States Environmental Protection Agency (EPA) (2025) Measuring Heat Islands. Available at: https://www.epa.gov/heatislands/measuring-heat-islands (Accessed: 25 April 2025).\nWilby, R.L. (2003). ‘Past and projected trends in London’s urban heat island’, Weather, 58: 251-260.\nWorld Health Organization. (2024) Heat and health. Available at: https://www.who.int/news-room/fact-sheets/detail/climate-change-heat-and-health (Accessed: 20 April 2025)."
  },
  {
    "objectID": "index.html#project-summary",
    "href": "index.html#project-summary",
    "title": "CASA0025 Group Project – Heat Stress Vulnerability Index (HSVI)",
    "section": "",
    "text": "Fill in the sections below to provide a brief summary of your project. Each section should have no more than 100 words. Do not edit any of the headings.\n\n\nWhat is the problem you’re trying to address using this application?\nUrban areas are becoming increasingly warmer than their surrounding areas known as the Urban Heat Island (UHI) effect (Wu et al., 2021). Moreover, heat stress is the leading cause of weather-related deaths and can exacerbate underlying illnesses (WHO, 2024). Studies have shown that estimates of heat-related mortality vary significantly depending on whether residents are assumed to acclimatise to local or city-wide temperatures (Shindell, 2024). Therefore, a web application that integrates temperature data, acclimatisation factors, and demographic vulnerability at a higher resolution would improve localised policy improvements and safety measures.\n\n\n\nWho are you building this application for? How does it address a need this community has?\nThis application is designed for various stakeholders who play a role in protecting London from extreme heat. These include governing authorities, public health bodies, and infrastructure providers. ​​It allows users to identify heat hotspots across the city in near real-time. This improves on static snapshot data (Arup, 2024), enabling more dynamic heat risk management. The application can also be used to inform city-wide policies, and enable localised public health responses during heat waves. Finally, it can be used to evaluate how infrastructure impacts heat stress and encourage precautionary and safety measures.\n\n\n\nWhat data are you using?\nGeospatial datasets from various sources are used: Sentinel-2 satellite imagery for NDVI (vegetation health), Landsat 8 Tier 1 for land surface temperature, Ordnance Survey for building mass density, and Nomis census data to capture old age demographics. These datasets are integrated and analysed to produce an index of heat vulnerability across urban areas.\n\n\n\nLayer/Factor\nDataset\nResolution\nTimeframe\nLink\n\n\n\n\nPopulation density (elderly)\ncensus2021-ts007-msoa.csv\nVector (MSOA)\nAs at 2021\nONS Census 2021\n\n\nNDVI\nSentinel 2 Bands 4 and 8\n10m\n3-4 days\nEarth Engine Data Catalog Sentinel-2\n\n\nTemperature (LST)\nLandsat 8 Surface Temperature Band 10\n30m\n16 days ; Month filter:6-9\nEarth Engine Data Catalog Landsat 8\n\n\nBuilding height and density\nOrdnance Survey National Geographic Database (OS NGD) Buildings\nvector\n2025\nOS NGD Documentation\n\n\n\n\n\n\nHow are you using this data to address the problem?\nThis application was built using Streamlit and integrates with Google Earth Engine (GEE). Data is fetched from GEE (Sentinel-2 for vegetation, Landsat 8 for temperature), OS NGD and the UK census. The index was created by first inverting the NDVI values, since more vegetation lowers heat risk, and then scaling all datasets between 0 and 1 using MinMaxScaler before combining them. Every factor is then weighted equally at 25%, and the weighted scores are summed to generate a final Heat Stress Vulnerability Index (HSVI). The results are then presented through an interactive map, enabling stakeholders to identify areas most at risk.\n\n\n\nHow does your application’s interface work to address the needs of your end user?\nThe interface features a dual-panel design for HSVI calculation. The left-control panel allows users to select data aggregated at different geographic levels (LAD or council), date ranges, and map topics (overall index or specific factors like NDVI, temperature, elderly population, and building mass density). The right panel displays responsive interactive choropleth maps and bar charts showing top 10 areas needing prior actions to tackle heat stress. Users can also download CSV files for external analysis. This design helps users identify vulnerable communities and understand specific heat-risk factors, supporting future interventions."
  },
  {
    "objectID": "index.html#the-application",
    "href": "index.html#the-application",
    "title": "CASA0025 Group Project – Heat Stress Vulnerability Index (HSVI)",
    "section": "",
    "text": "Each time users change map layers in application, please use “Reset APP” botton to refresh the page to avoid cache problmes.\nApplication Website: https://casa0025-test.streamlit.app"
  },
  {
    "objectID": "index.html#how-it-works",
    "href": "index.html#how-it-works",
    "title": "CASA0025 Group Project – Heat Stress Vulnerability Index (HSVI)",
    "section": "",
    "text": "Use this section to explain how your application works using code blocks and text explanations (no more than 500 words excluding code):\nClick here to access the repo to find Home.py which includes all codes for the application.\n\n\n\nTechnical Walkthrough\n\n\n\n\nUrban heat disproportionately affects segments of the population; people over the age of 65 represent the largest of these groups. We use this group as a proxy for vulnerable population groups within our application. The data used to size this group is from the UK 2021 Census. Data is aggregated at the lowest available level of aggregation (MSOA) and is summed together.\nThis is then divided by the total population for that location “Total Number of Usual Residents” to arrive at a Percentage of the population aged 65 and over. The rate value is used as part of the HSVI, however, in practice there are minor differences when compared to using absolute counts, so rates are preferred.\n# 2️ Convert GeoDataFrame → EE FeatureCollection\n                    if st.session_state.london_boroughs_over_65 is None:\n                        # now we're going to add in the vector data for the london boroughs for number of people over 65 from a geojson file\n                        # london_boroughs_over_65 = gp.read_file('data/london_percentage_of_population_over_65.geojson')#.head(10).to_crs(4326)\n                        london_boroughs_over_65 = pd.read_parquet('data/london_percentage_of_population_over_65.parquet.gzip')\n\n\n\n                        # load the lsoa level geometries\n                        # gdf_lsoas = pd.read_parquet('data/london_lsoas_2011_mapping_file.parquet.gzip')\n                        gdf_lsoas = pd.read_parquet('data/london_msoas_2021_mapping_file.parquet.gzip')\n                        # convert the wkt geometry to a shapely geometry\n                        gdf_lsoas[\"geometry\"] = gdf_lsoas[\"geometry\"].apply(shapely.wkt.loads)\n                        # convert this to a geodataframe\n                        gdf_lsoas = gp.GeoDataFrame(gdf_lsoas, geometry=\"geometry\", crs=4326)\n                        # filter the LAD11NM column to match the users  \n                        gdf_boroughs = gdf_lsoas[gdf_lsoas[\"LAD11NM\"] == st.session_state.selected_council]\n                        gdf_boroughs = gdf_boroughs[[\"MSOA21CD\"]].rename(columns={\"MSOA21CD\":\"geography code\"})\n\n\n                        # do a spatial join to get the vulnerable population data for the selected council\n                        london_boroughs_over_65 = london_boroughs_over_65.merge(gdf_boroughs, on=\"geography code\")\n\n                        # convert the wkt geometry to a shapely geometry\n                        london_boroughs_over_65[\"geometry\"] = london_boroughs_over_65[\"geometry\"].apply(shapely.wkt.loads)\n                        # convert this to a geodataframe\n                        london_boroughs_over_65 = gp.GeoDataFrame(london_boroughs_over_65, geometry=\"geometry\", crs=4326)\n\n\n                        # add this to session state\n                        st.session_state.london_boroughs_over_65 = london_boroughs_over_65\n                    else:\n                        london_boroughs_over_65 = st.session_state.london_boroughs_over_65\n\n\n\n\n                    # calculate the midpoint of london\n                    london_midpoint_latitude, london_midpoint_longitude = london_boroughs_over_65.to_crs(4326).geometry.centroid.y.mean(), london_boroughs_over_65.to_crs(4326).geometry.centroid.x.mean()\n                    \n\n                    # rename columns for the map\n                    london_boroughs_over_65 = london_boroughs_over_65.rename(columns={\"pct_over_65_pop\":\"Population over 65 %\",\n                                                                                      \"total_pop_over_65_years_old\":\"Total Population over 65\",\n                                                                                      \"total_pop\":\"Total Population\"})\n                    london_boroughs_over_65 = london_boroughs_over_65.drop(columns=[\"date\",\"city\"])\n                    # round the % population over 65 to 2 decimal places\n                    london_boroughs_over_65[\"Population over 65 %\"] = (london_boroughs_over_65[\"Population over 65 %\"] * 100).round(2)\n\n                    if st.session_state.london_boroughs_over_65_map is None:\n                        # we'll plot this on a folium map\n                        m = london_boroughs_over_65.explore(\"Population over 65 %\", tiles=\"CartoDB.Positron\", cmap=\"Blues\", scheme=\"Quantiles\", legend_title=\"Population over 65\", style_kwds={'weight': 1})\n\n\n\nHealthy vegetation cools surrounding areas through shade and evapotranspiration which is why it is incorporated in the index. Healthy plants absorb red light and reflect near-infrared (NIR) light. NDVI captures the contrast between NIR and Red reflectance, allowing us to identify areas of healthy vegetation. Areas with NDVI values close to 1 indicate healthy vegetation, while low or negative values suggest sparse vegetation.\nNDVI is calculated using this formula:\n\\[\nNDVI = \\frac{(NIR - Red)}{(NIR + Red)}\n\\]\nWhere:\n\n\\(NDVI\\): Normalized Difference Vegetation Index\n\n\\(NIR\\): Reflectance in the Near-Infrared band\n\n\\(Red\\): Reflectance in the Red band\n\nSentinel-2 data was cloud-filtered and combined using the median value of the available images in GEE. NDVI values were calculated from band 4 (Red) and band 8 (Near-infrared). Then spatially aggregated by borough using a median reducer at 10m resolution.\n# now we're going to use the lad data to get the NDVI\n                    if st.session_state.gdf_results is None:\n\n\n                        # 2️ Convert GeoDataFrame → EE FeatureCollection\n                        ee_boroughs = geemap.geopandas_to_ee(gdf_boroughs, geodesic=False)\n                        st.session_state.ee_boroughs = ee_boroughs\n                        # 3️ Build Sentinel‑2 NDVI composite\n                        sentinel = (\n                            ee.ImageCollection('COPERNICUS/S2_SR')\n                            .filterBounds(ee_boroughs)\n                            .filterDate(one_year_ago, today)\n                            .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\n                            .median()\n                            .clip(ee_boroughs)\n                        )\n\n                        # this was the default code for the NDVI\n                        ndvi = sentinel.normalizedDifference(['B8', 'B4']).rename('NDVI')\n                        st.session_state.ndvi = ndvi\n\n                        # 4️ Sum NDVI per borough\n                        fc_results = ndvi.reduceRegions(\n                            collection=ee_boroughs,\n                            reducer=ee.Reducer.median(),\n                            scale=10,\n                            crs='EPSG:27700'\n                        )\n                        \n                        # 5️⃣Pull results client‑side as GeoJSON → GeoDataFrame\n                        geojson = fc_results.getInfo()\n                        \n                        gdf_results = gp.GeoDataFrame.from_features(geojson['features']).rename(columns={'NAME': 'MSOA Name',\"median\": \"NDVI\"})\n                        # for ndvi we will need to invert these values \n                        gdf_results[\"NDVI\"] = 1 / gdf_results[\"NDVI\"]\n\n                        st.session_state.gdf_results = gdf_results\n\n\n\nLand Surface Temperature (LST) represents heat energy emitted by land, buildings, and other surfaces, serving as an indirect measure of air temperature during heat waves (United States Environmental Protection Agency, 2025). Using Landsat 8 Surface Temperature Band 10 in GEE, processed LST was derived for summer months (June-September) when peak heat conditions are experienced.\nWe filtered out cloudy images, before applying a median reducer and a water mask excluding water bodies to focus on artificial surfaces that retain more heat, relevant to urban populations. Spatial aggregation was finally done at LSOA and Borough levels.\n # load the data and apply the relevant filters and functions\n                    #.filter(ee.Filter.calendarRange(6, 9,'month')) \\  may apply a similar seasonal filter here\n                    if st.session_state.date_range_selection == \"Yes\":\n                        landsat = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n                        .filterDate(st.session_state.user_selected_start_date, st.session_state.user_selected_end_date) \\\n                        .filter(ee.Filter.calendarRange(6, 9, 'month'))\\\n                        .filterBounds(ee_boroughs) \\\n                        .filter(ee.Filter.lt(\"CLOUD_COVER\", 15)) \\\n                        .map(applyScaleFactors) \\\n                        .select('ST_B10').map(celsius) \\\n                        .reduce(ee.Reducer.median()) \\\n                        .clip(ee_boroughs)\n                    elif st.session_state.date_range_selection == \"No\":\n                        landsat = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n                        .filterDate(one_year_ago, today) \\\n                        .filter(ee.Filter.calendarRange(6, 9, 'month'))\\\n                        .filterBounds(ee_boroughs) \\\n                        .filter(ee.Filter.lt(\"CLOUD_COVER\", 15)) \\\n                        .map(applyScaleFactors) \\\n                        .select('ST_B10').map(celsius) \\\n                        .reduce(ee.Reducer.median()) \\\n                        .clip(ee_boroughs)\n                    # mask out water in London to detect more accurate LST result\n                    # Generate a water mask.\n                    water = ee.Image(\"JRC/GSW1_4/GlobalSurfaceWater\").select(\"occurrence\")\n                    notWater = water.mask().Not()\n                    temperature_layer = landsat.updateMask(notWater)\n\n                    st.session_state.temperature_layer = temperature_layer\n\n                    # 4️ Sum NDVI per borough\n                    temperature_results = temperature_layer.reduceRegions(\n                        collection=ee_boroughs,\n                        reducer=ee.Reducer.median(),\n                        scale=10,\n                        crs='EPSG:27700'\n                    )\n                            \n                    # 5️⃣Pull results client‑side as GeoJSON → GeoDataFrame\n                    geojson = temperature_results.getInfo()\n                    \n                    temperature_gdf_results = gp.GeoDataFrame.from_features(geojson['features']).rename(columns={'NAME': 'MSOA Name',\"median\": \"surface_temperature\"})\n\n\n\nDensely built environments contribute to higher heat absorption and slower cooling. Therefore, Building Mass Density (BMD) is considered as part of the Urban Heat Island (UHI) index. BMD has been calculated at both the LSOA and Borough levels.\nThe Ordnance Survey National Geographic Database (OS NGD) was used as the most complete and authoritative building dataset available in Great Britain. OS NGD was chosen over OpenStreetMap (OSM) due to its more comprehensive and consistent height attribution, which is sparse and unreliable in OSM (Bernard et al., 2022).\nBMD was calculated using the following formula:\n\\[\nBmd = \\frac{\\sum (H_i \\times A_i)}{A_{admin}}\n\\]\nWhere:\n\n\\(Bmd\\): Building Mass Density\n\\(H_i\\): Height of building \\(i\\) (in metres)\n\\(A_i\\): Footprint area of building \\(i\\) (in square metres)\n\\(A_{admin}\\): Total area of the administrative region (in square metres)\n\n## Process total building volumes per lsoa\n# This is split into batches to prevent time out issues.\n\n# Get list of all LSOA codes\nlsoa_codes = con.execute(\"\"\"\n    SELECT DISTINCT LSOA21CD\n    FROM london_lsoa;\n    \"\"\").fetchdf()['LSOA21CD'].tolist()\n\n# Split into batches\nbatch_size = 250\nbatches = [lsoa_codes[i:i + batch_size] for i in range(0, len(lsoa_codes), batch_size)]\n\n# Create the table before the loop if it doesn't exist\ncon.execute(\"\"\"\n    CREATE TABLE IF NOT EXISTS london_LSOAs_vol (\n        LSOA21CD VARCHAR PRIMARY KEY,\n        borough VARCHAR,\n        building_count INTEGER,\n        total_volume DOUBLE,\n        geom GEOMETRY\n    )\n\"\"\")\n\nfor batch in batches:\n    # Convert to SQL IN clause\n    code_list = ','.join(f\"'{code}'\" for code in batch)\n\n    # create query to insert data into new london_LSOAs_vol table\n    query = f\"\"\"\n        INSERT INTO london_LSOAs_vol\n        SELECT\n            l.LSOA21CD,\n            l.Borough AS borough,\n            COUNT(*) AS building_count,\n            SUM(b.volume) AS total_volume,\n            l.geom\n        FROM london_lsoa l\n        JOIN buildings b\n        ON ST_Intersects(l.geom, ST_GeomFromText(b.geometry))\n        WHERE l.LSOA21CD IN ({code_list})\n        GROUP BY l.LSOA21CD, l.geom, l.Borough;\n    \"\"\"\n    # execute the query created above\n    con.execute(query)\n\n\n# Calculate the building mass density\n# Building Mass Density = LSOA area x total building volume\n\n# Calculate area for each LSOA (assuming CRS in meters)\ncon.execute(\"\"\"\n    ALTER TABLE london_LSOAs_vol ADD COLUMN area_m2 DOUBLE;\n    UPDATE london_LSOAs_vol\n    SET area_m2 = ST_Area(geom);\n\"\"\")\n\n# Calculate building mass density for each LSOA\ncon.execute(\"\"\"\n    ALTER TABLE london_LSOAs_vol ADD COLUMN building_mass_density DOUBLE;\n    UPDATE london_LSOAs_vol\n    SET building_mass_density = total_volume / area_m2;\n\"\"\")\n\n\n\nThen we combine four factors above to calculate the index:\n# okay so now we're going to normalise the data values  using sklearn min max scaler\n                    scaler = MinMaxScaler()\n                    # first we'll get the columns we want to normalise\n                    columns_to_normalise = [\"ndvi\",\"surface_temperature\",\"pct_over_65_pop\",\"building_density\"]\n                    for column in columns_to_normalise:\n                        raw_index_values_gdf_boroughs[f\"{column}_normalised\"] = scaler.fit_transform(raw_index_values_gdf_boroughs[[column]])\n                    # st.write(\"Normalised dataframe\")\n                    # st.dataframe(raw_index_values_gdf_boroughs)\n                    # ------------------------------------------------------------\n                    normalised_columns = [x for x in raw_index_values_gdf_boroughs.columns if \"normalised\" in x]\n                    for column in normalised_columns:\n                        # now we're going to weight this by 25% for each of the normalised values\n                        raw_index_values_gdf_boroughs[f\"{column}_weighted\"] = raw_index_values_gdf_boroughs[column] * 0.25\n                    # st.write(\"Weighted dataframe\")\n                    weighted_df = raw_index_values_gdf_boroughs[[\"borough_name\"]+[x for x in raw_index_values_gdf_boroughs.columns if \"weighted\" in x] + [\"geometry\"]]\n                    # st.dataframe(weighted_df)\n                    # ------------------------------------------------------------\n                    # now lastly we're going to sum these up to get the final index values\n                    weighted_df[\"index_value\"] = weighted_df[[x for x in weighted_df.columns if \"weighted\" in x]].sum(axis=1)\n                    weighted_columns = [x for x in weighted_df.columns if \"weighted\" in x]\n                    # st.write(\"Final index dataframe\")\n                    # st.dataframe(weighted_df.rename(columns={\"borough_name\":\"Location\"}).drop(columns=[\"geometry\"]))\n                    # ------------------------------------------------------------"
  },
  {
    "objectID": "index.html#reference",
    "href": "index.html#reference",
    "title": "CASA0025 Group Project – Heat Stress Vulnerability Index (HSVI)",
    "section": "",
    "text": "Arup. (2024) Urban heat snapshot. Available at: https://www.arup.com/insights/publication-urban-heat-snapshot/ (Accessed: 20 April 2025).\nBernard, J. et al. (2022) ‘Estimation of missing building height in OpenStreetMap data: a French case study using GeoClimate 0.0.1’, Geoscientific Model Development, 15(19), pp. 7505–7532. Available at: (https://doi.org/10.5194/gmd-15-7505-2022).\nShindell, D., Hunter, R., Faluvegi, G., & Parsons, L (2024). ‘Premature deaths due to heat exposure: The potential effects of neighborhood-level versus city-level acclimatization within US cities’, GeoHealth, 8.\nUnited States Environmental Protection Agency (EPA) (2025) Measuring Heat Islands. Available at: https://www.epa.gov/heatislands/measuring-heat-islands (Accessed: 25 April 2025).\nWilby, R.L. (2003). ‘Past and projected trends in London’s urban heat island’, Weather, 58: 251-260.\nWorld Health Organization. (2024) Heat and health. Available at: https://www.who.int/news-room/fact-sheets/detail/climate-change-heat-and-health (Accessed: 20 April 2025)."
  }
]